{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro:\n",
    "My client, Meagher + Geer, PLLP faced a data-centric issue on their case that required the cleaning, aggregating, and visualization of a large and complex set of data to help support their claim in a workers compensation suit. This was required for them to provide further context utilizing the quantitative data provided to them on their clients assumed working times over a multi-year period in the form of millions of raw time stamps and work functions performed by their client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To tackle this issue, Meagher + Geer, PLLP hired Slater Bernstein consulting to perform the following key Analytical functions:\n",
    "\n",
    "· Extract, transform and load the raw data into a normalized table  containing the timestamps and work functions performed by their client over the outlined period. The raw tables came in the form of CSV files which were then extracted to a SQL schema.\n",
    "    - *For confidentiality purposes, only column headers and dummy data will be displayed for all example visualizations.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Control Number</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>DoW</th>\n",
       "      <th>Record Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EML00149132</td>\n",
       "      <td>2018-07-10 11:42:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>11:42:00 AM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EML00149152</td>\n",
       "      <td>2018-07-10 13:59:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>1:59:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EML00162279</td>\n",
       "      <td>2018-07-10 15:58:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>3:58:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EML00162275</td>\n",
       "      <td>2018-07-10 16:01:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>4:01:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EML00162287</td>\n",
       "      <td>2018-07-10 16:02:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>4:02:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>EML00162274</td>\n",
       "      <td>2018-07-10 16:02:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>4:02:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>EML00162271</td>\n",
       "      <td>2018-07-10 16:09:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>4:09:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>EML00162266</td>\n",
       "      <td>2018-07-10 16:17:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>4:17:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EML00162265</td>\n",
       "      <td>2018-07-10 16:20:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>4:20:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EML00162264</td>\n",
       "      <td>2018-07-10 16:21:00</td>\n",
       "      <td>7/10/2018</td>\n",
       "      <td>4:21:00 PM</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Email</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Control Number            DateTime       date         time      DoW  \\\n",
       "0    EML00149132 2018-07-10 11:42:00  7/10/2018  11:42:00 AM  Tuesday   \n",
       "1    EML00149152 2018-07-10 13:59:00  7/10/2018   1:59:00 PM  Tuesday   \n",
       "2    EML00162279 2018-07-10 15:58:00  7/10/2018   3:58:00 PM  Tuesday   \n",
       "3    EML00162275 2018-07-10 16:01:00  7/10/2018   4:01:00 PM  Tuesday   \n",
       "4    EML00162287 2018-07-10 16:02:00  7/10/2018   4:02:00 PM  Tuesday   \n",
       "5    EML00162274 2018-07-10 16:02:00  7/10/2018   4:02:00 PM  Tuesday   \n",
       "6    EML00162271 2018-07-10 16:09:00  7/10/2018   4:09:00 PM  Tuesday   \n",
       "7    EML00162266 2018-07-10 16:17:00  7/10/2018   4:17:00 PM  Tuesday   \n",
       "8    EML00162265 2018-07-10 16:20:00  7/10/2018   4:20:00 PM  Tuesday   \n",
       "9    EML00162264 2018-07-10 16:21:00  7/10/2018   4:21:00 PM  Tuesday   \n",
       "\n",
       "  Record Type  \n",
       "0       Email  \n",
       "1       Email  \n",
       "2       Email  \n",
       "3       Email  \n",
       "4       Email  \n",
       "5       Email  \n",
       "6       Email  \n",
       "7       Email  \n",
       "8       Email  \n",
       "9       Email  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import SQLAlchemyError\n",
    "from IPython.display import display\n",
    "import os\n",
    "\n",
    "#Creating Connection between MySQL DataBase\n",
    "try:\n",
    "    mydb = mysql.connector.connect(\n",
    "        host = os.getenv('host'),\n",
    "        user = os.getenv('user'),\n",
    "        password = os.getenv('pass'),\n",
    "        database = \"HvT\"\n",
    "    )\n",
    "    curser = mydb.cursor(buffered=True)\n",
    "    curser.execute(\"use HvT\")\n",
    "\n",
    "except mysql.connector.Error as err:\n",
    "    print(\"An error occurred:\", err)\n",
    "\n",
    "#Connection to MySQL for access to load into MySQL Database\n",
    "engine = create_engine(f\"mysql+mysqlconnector://{os.getenv('user')}:{os.getenv('pass')}@localhost:3306/HvT\")\n",
    "\n",
    "# Loading raw data from CSV -> Dataframe for staging -> MySQL DataTable\n",
    "emailsDf = pd.read_csv('..\\\\RAW\\\\Haralson Email Messages.csv')\n",
    "emailsDf['Sort Date/Time - Offset'] = pd.to_datetime(emailsDf['Sort Date/Time - Offset'])\n",
    "print(emailsDf.info())\n",
    "emailsDf.to_sql('Emails', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "messagesDf = pd.read_csv('..\\\\RAW\\\\Teams Messages.csv')\n",
    "messagesDf['Sort Date/Time - Offset'] = pd.to_datetime(messagesDf['Sort Date/Time - Offset'])\n",
    "print(messagesDf.info())\n",
    "messagesDf.to_sql('Messages', con=engine, if_exists='replace', index=False)\n",
    "\n",
    "#...\n",
    "\n",
    "# Certain CSV's were grouped by year and needed to be appended to normalize the dataset\n",
    "SAP20 = pd.read_csv('..\\\\RAW\\\\SAP REPORT 2020 - TS 843.csv')\n",
    "SAP21 = pd.read_csv('..\\\\RAW\\\\SAP REPORT 2021 - TS 844.csv')\n",
    "SAP22 = pd.read_csv('..\\\\RAW\\\\SAP REPORT 2022 - TS 845.csv')\n",
    "SAP23 = pd.read_csv('..\\\\RAW\\\\SAP REPORT 2023 - TS 840.csv')\n",
    "\n",
    "sap20_24Df = pd.concat([SAP20, SAP21, SAP22, SAP23], ignore_index=True)\n",
    "sap20_24Df['Time Stamp'] = pd.to_datetime(sap20_24Df['Time Stamp'], format='mixed', dayfirst=True)\n",
    "print(sap20_24Df.info())\n",
    "\n",
    "#Creating connection to the MySQL server set up above, then beginning the transactional connection\n",
    "try:\n",
    "    connection = engine.connect()\n",
    "\n",
    "    trans = connection.begin()\n",
    "\n",
    "    #Since the concatenated dataframes are very large, the rows must be loaded in chunks of 10,000\n",
    "    try:\n",
    "        sap20_24Df.to_sql('SAP20-23', con=engine, if_exists='replace', index=False, chunksize=10000)\n",
    "        print(\"LFG\")\n",
    "        trans.commit()\n",
    "    except SQLAlchemyError as e:\n",
    "        print({e})\n",
    "        connection.rollback()\n",
    "    finally:\n",
    "        connection.close()\n",
    "\n",
    "except SQLAlchemyError as e:\n",
    "    print({e})\n",
    "\n",
    "\n",
    "#For display purposes, a control set of 10 rows of data is taken from the Emails table\n",
    "curser.execute(\"SELECT `Control Number`, `Sort Date/Time - Offset` as DateTime, `date`, `time`, `DoW`, `Record Type` FROM Emails;\")\n",
    "emails = curser.fetchall()\n",
    "headers = [i[0] for i in curser.description]\n",
    "emailsDf = pd.DataFrame(emails, columns=[headers], index=None)\n",
    "display(emailsDf.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several questions needed to be answered using this data, and after gathering requirements with my client, these four questions were deemed most integral to answering their business problem:\n",
    "    - When did the client start/end their work day on average?\n",
    "    - how many interactions contributed to their daily online footprint?\n",
    "    - When were they most/least active?\n",
    "    - How many overtime hours did the client accumulate total/on average?\n",
    "\n",
    "This brought me to my next key analytical function:\n",
    "\n",
    "· Group and aggregate the raw timestamps to gather information on their client’s first and last work function performed each day, as well as how many work functions were performed and my data driven opinion on working hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>startTime</th>\n",
       "      <th>endTime</th>\n",
       "      <th>timestamp_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-09-26</td>\n",
       "      <td>2020-09-26 07:16:00</td>\n",
       "      <td>2020-09-26 21:29:00</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-09-27</td>\n",
       "      <td>2020-09-27 05:02:00</td>\n",
       "      <td>2020-09-27 22:31:00</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-09-28</td>\n",
       "      <td>2020-09-28 06:34:00</td>\n",
       "      <td>2020-09-28 23:57:00</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-09-29</td>\n",
       "      <td>2020-09-29 05:28:00</td>\n",
       "      <td>2020-09-29 23:03:00</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-09-30</td>\n",
       "      <td>2020-09-30 07:13:00</td>\n",
       "      <td>2020-09-30 22:25:00</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020-10-01</td>\n",
       "      <td>2020-10-01 05:46:00</td>\n",
       "      <td>2020-10-01 19:08:00</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>2020-10-02 06:22:00</td>\n",
       "      <td>2020-10-02 18:57:00</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-10-04</td>\n",
       "      <td>2020-10-04 08:35:00</td>\n",
       "      <td>2020-10-04 17:33:00</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-10-05</td>\n",
       "      <td>2020-10-05 06:54:00</td>\n",
       "      <td>2020-10-05 20:05:00</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>2020-10-06 06:40:00</td>\n",
       "      <td>2020-10-06 19:46:00</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date           startTime             endTime timestamp_count\n",
       "0  2020-09-26 2020-09-26 07:16:00 2020-09-26 21:29:00             123\n",
       "1  2020-09-27 2020-09-27 05:02:00 2020-09-27 22:31:00              43\n",
       "2  2020-09-28 2020-09-28 06:34:00 2020-09-28 23:57:00              92\n",
       "3  2020-09-29 2020-09-29 05:28:00 2020-09-29 23:03:00             420\n",
       "4  2020-09-30 2020-09-30 07:13:00 2020-09-30 22:25:00              68\n",
       "5  2020-10-01 2020-10-01 05:46:00 2020-10-01 19:08:00              65\n",
       "6  2020-10-02 2020-10-02 06:22:00 2020-10-02 18:57:00              53\n",
       "7  2020-10-04 2020-10-04 08:35:00 2020-10-04 17:33:00              20\n",
       "8  2020-10-05 2020-10-05 06:54:00 2020-10-05 20:05:00             151\n",
       "9  2020-10-06 2020-10-06 06:40:00 2020-10-06 19:46:00              64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row Count: 1010\n"
     ]
    }
   ],
   "source": [
    "# First all tables needed to be concatenated into a combined table with the date, mininum, maximum, and count of timestamp for each medium\n",
    "curser.execute(\"\"\"\n",
    "DROP TABLE IF EXISTS CombinedStamps;\n",
    "CREATE TABLE CombinedStamps AS\n",
    "SELECT \n",
    "    DATE(`Sort Date/Time - Offset`) AS date, \n",
    "    MIN(`Sort Date/Time - Offset`) AS first_timestamp, \n",
    "    MAX(`Sort Date/Time - Offset`) AS last_timestamp, \n",
    "    COUNT(`Sort Date/Time - Offset`) AS timestamp_count\n",
    "FROM \n",
    "    Emails\n",
    "GROUP BY \n",
    "    DATE(`Sort Date/Time - Offset`)\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    DATE(`Sort Date/Time - Offset`) AS date, \n",
    "    MIN(`Sort Date/Time - Offset`) AS first_timestamp, \n",
    "    MAX(`Sort Date/Time - Offset`) AS last_timestamp, \n",
    "    COUNT(`Sort Date/Time - Offset`) AS timestamp_count\n",
    "FROM \n",
    "    Messages\n",
    "GROUP BY \n",
    "    DATE(`Sort Date/Time - Offset`)\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    DATE(`Date/time submitted`) AS date, \n",
    "    MIN(`Date/time submitted`) AS first_timestamp, \n",
    "    MAX(`Date/time submitted`) AS last_timestamp, \n",
    "    COUNT(`Date/time submitted`) AS timestamp_count\n",
    "FROM \n",
    "    ESKER\n",
    "GROUP BY \n",
    "    DATE(`Date/time submitted`)\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    DATE(`Time Stamp`) AS date, \n",
    "    MIN(`Time Stamp`) AS first_timestamp, \n",
    "    MAX(`Time Stamp`) AS last_timestamp, \n",
    "    COUNT(`Time Stamp`) AS timestamp_count\n",
    "FROM \n",
    "    `SAP20-23`\n",
    "GROUP BY \n",
    "    DATE(`Time Stamp`)\n",
    "\n",
    "UNION ALL\n",
    "\n",
    "SELECT \n",
    "    DATE(`Sort Date/Time - Offset`) AS date, \n",
    "    MIN(`Sort Date/Time - Offset`) AS first_timestamp, \n",
    "    MAX(`Sort Date/Time - Offset`) AS last_timestamp, \n",
    "    COUNT(`Sort Date/Time - Offset`) AS timestamp_count\n",
    "FROM \n",
    "    `TS20-23`\n",
    "GROUP BY \n",
    "    DATE(`Sort Date/Time - Offset`);\n",
    "               \"\"\", multi=True)\n",
    "\n",
    "\n",
    "# From there the query simply needed to be tailored to answer the initial questions:\n",
    "#   - SELECT statement gathers the earliest and latest timestamp from the combined table as well as a grand sum of interactions for all timestamps\n",
    "#   - WHERE statement filters first timestamps by the earliest reasonable time the client would start their work day\n",
    "#   - GROUP BY statement will group the SELECT data by recorded date, most notably the timestamp counts which allow me to gather all presumed work functions for each date\n",
    "#   - HAVING statement will filter all data by the requested observable period\n",
    "curser.execute(\"\"\"\n",
    "SELECT\n",
    "    `date`, \n",
    "    MIN(first_timestamp) as startTime,\n",
    "    MAX(last_timestamp) as endTime,\n",
    "    sum(timestamp_count) as timestamp_count\n",
    "FROM \n",
    "    CombinedStamps\n",
    "WHERE \n",
    "    HOUR(first_timestamp) >= '05:00:00'\n",
    "GROUP BY \n",
    "    `date`\n",
    "HAVING \n",
    "    `date` BETWEEN '2020-09-26' AND '2023-08-09';\n",
    "               \"\"\")\n",
    "DateTimeAll = curser.fetchall()\n",
    "headers = [i[0] for i in curser.description]\n",
    "DateTimeAllDf = pd.DataFrame(DateTimeAll, columns=[headers], index=None)\n",
    "display(DateTimeAllDf.head(10))\n",
    "print(\"Row Count: \" + str(len(DateTimeAllDf)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
